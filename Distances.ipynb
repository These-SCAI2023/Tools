{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, glob , spacy, json, sklearn, os\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.cluster import AgglomerativeClustering\n",
    "#from sklearn.metrics import pairwise_distances\n",
    "#from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lire_fichier (chemin):\n",
    "    f = open(chemin , encoding = 'utf−8')\n",
    "    chaine = f.read ()\n",
    "    f.close ()\n",
    "    return chaine\n",
    "\n",
    "def liste_resultats(texte, nlp= spacy.load(\"fr_core_news_sm\")):\n",
    "    doc = nlp(texte)\n",
    "    list_resultats =[]\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_==\"LOC\":\n",
    "            list_resultats.append(ent.text)\n",
    "    return (list_resultats)\n",
    "\n",
    "def get_distances(texte1, texte2, N=1, liste_name =[\"jaccard\", \"braycurtis\",\"dice\", \"cosinus\"] ):\n",
    "    dico = {}\n",
    "    for metric_name in liste_name :\n",
    "        dico[metric_name] = []\n",
    "        liste_resultat_dist2 = []\n",
    "        for n_max in range(1, N+1):###range([min, default = 0], max, [step, default = 1]) \n",
    "            V = CountVectorizer(ngram_range=(1,n_max ), analyzer='char') \n",
    "            X = V.fit_transform([texte1, texte2]).toarray()\n",
    "            if metric_name!= \"cosinus\" :  \n",
    "                dist = DistanceMetric.get_metric(metric_name)     \n",
    "                distance_tab1=dist.pairwise(X)\n",
    "                liste_resultat_dist2.append(distance_tab1[0][1])\n",
    "            else: \n",
    "                distance_tab1=sklearn.metrics.pairwise.cosine_distances(X) \n",
    "                liste_resultat_dist2.append(distance_tab1[0][1])\n",
    "            dico[metric_name] = liste_resultat_dist2\n",
    "    return dico\n",
    "\n",
    "def stocker(chemin, contenu):\n",
    "    w =open(chemin, \"w\")\n",
    "    w.write(json.dumps(contenu , indent = 2))\n",
    "    w.close()\n",
    "    print(chemin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_corpora = \"../data_Audoux/corpora/\"## dans \"corpora\" un subcorpus = toutes les versions 'un texte'\n",
    "\n",
    "\n",
    "for modele in [\"sm\",\"md\", \"lg\"]:\n",
    "    print(\"Starting with modèle %s\"%modele)\n",
    "    nlp = spacy.load(\"fr_core_news_%s\"%modele)\n",
    "    for subcorpus in glob.glob(\"%s/*\"%path_corpora):\n",
    "        \n",
    "        print(\"Processing %s\"%subcorpus)\n",
    "        print(glob.glob(\"%s/*.txt\"%subcorpus))\n",
    "        for path in glob.glob(\"%s/*.txt\"%subcorpus): \n",
    "            print(path)\n",
    "            \n",
    "            path_output = \"%s_entites_%s.json\"%(path, modele)\n",
    "            print(path_output)\n",
    "            \n",
    "            if os.path.exists(path_output)==True:\n",
    "                print(f\"Already Done {path_output}\")\n",
    "                \n",
    "                continue\n",
    "           \n",
    "            filename = re.split(\"/\", path)[-1]\n",
    "            auteur, version, _ = re.split(\"_|\\.\", filename)\n",
    "            texte = lire_fichier(path)\n",
    "            entites = liste_resultats(texte, nlp)\n",
    "            #entites= [\"toto\", \"titi\"]\n",
    "            \n",
    "            stocker(path_output, entites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_evaluate = path_corpora \n",
    "# = \"../data_Audoux/corpora/\"\n",
    "\n",
    "for subcorpus in glob.glob(\"%s/*\"%path_corpora):\n",
    "    if os.path.isdir(subcorpus) ==False:\n",
    "        continue\n",
    "            \n",
    "    print(subcorpus)\n",
    "   \n",
    "    dico_out = {}\n",
    "    dist_txt = {}\n",
    "    for file_type in [\"txt\", \"json\"]:\n",
    "        liste_compare = []\n",
    "        for path_file in glob.glob(\"%s/*.%s\"%(subcorpus, file_type)):\n",
    "            \n",
    "            filename = re.split(\"/\", path_file)[-1]\n",
    "            #print(filename)\n",
    "            elems = re.split(\"_|\\.\", filename)\n",
    "            auteur, version, modele = elems[0], elems[1], elems[-2]\n",
    "            print(\"ELEMS\", modele)\n",
    "            if file_type ==\"txt\":\n",
    "                liste_compare.append([version, lire_fichier(path_file)])\n",
    "            else:\n",
    "                liste_compare.append([modele, lire_fichier(path_file)])\n",
    "        print([x[0]for x in liste_compare])\n",
    "        # liste_compare = [[version, toto[:1000]] for version, toto in liste_compare]#list comprehension\n",
    "        dico_out[file_type] = {}\n",
    "        for ID1 in range(len(liste_compare)):\n",
    "            version1 = liste_compare[ID1][0]\n",
    "            for ID2 in range(ID1+1, len(liste_compare)):\n",
    "                version2 = liste_compare[ID2][0]\n",
    "                dico_dist = get_distances(liste_compare[ID1][1], liste_compare[ID2][1], N=5)\n",
    "                paire = \"%s--%s\"%(version1, version2)\n",
    "                dico_out[file_type][paire] = dico_dist\n",
    "    stocker(\"%s_distances.json\"%subcorpus, dico_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COURBES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('./data_JSON_COURBES/AUDOUX_CORPORA/AUDOUX_distances.json') as json_data: \n",
    "    dist =json.load(json_data)\n",
    "\n",
    "# for i in dist.items():\n",
    "    # print(i)\n",
    "\n",
    "print(list(dist))\n",
    "# print(\"  \",dist['txt'][\"OCR--propre\"])\n",
    "# print(\"  \", dist['txt'][\"OCR--OCR\"])\n",
    "print(\"lg--propre\", dist['json'][\"lg--propre\"])\n",
    "print(\"propre--lg\", dist['json'][\"propre--lg\"])\n",
    "\n",
    "\n",
    "# dic_plot = {}\n",
    "# for cle, dic in dist.items(): \n",
    "    \n",
    "#     print(\"l'élément de clé\", cle)\n",
    "    \n",
    "#     for version, modele in dic.items():\n",
    "#         print(\"  \",version )\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        # for name_metric, liste in modele.items():\n",
    "        #     print(\"      \", name_metric)\n",
    "            \n",
    "        #     plt.plot(liste, label=name_metric)\n",
    "        # name_fig = \"%s_%s.png\"%(version, name_metric)\n",
    "        # print(\" nom de la figure \", name_fig)\n",
    "        # plt.legend(loc='upper left')\n",
    "        # plt.savefig(\"%s_%s.png\"%(version, name_metric))\n",
    "        # plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
